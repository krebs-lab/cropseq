{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "\n",
    "import phate\n",
    "import meld\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
    "\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "PDF_DIR = os.path.join(PROCESSED_DIR, \"pdf\")\n",
    "NOTEBOOK_DIR = os.path.join(BASE_DIR, \"notebooks\")\n",
    "\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "\n",
    "PROJECT_NAME = \"CropSeq-20-14\"\n",
    "\n",
    "def sfile(filename):\n",
    "    _fname = os.path.join(PDF_DIR, f\"{PROJECT_NAME}_merged_{filename}\")\n",
    "    print(f\"File save at '{_fname}'\")\n",
    "    return _fname\n",
    "\n",
    "\n",
    "# Checkpoint handling functions\n",
    "\n",
    "def save_checkpoint(adata_obj, filename, overwrite=False):\n",
    "    filename = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    if os.path.isfile(filename) and not overwrite:\n",
    "        raise FileExistsError(f\"File '{filename}' already exists\")\n",
    "    adata_obj.write_h5ad(filename)\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    filename = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        raise FileNotFoundError(f\"Cant find file '{filename}'\")\n",
    "    return sc.read_h5ad(filename)\n",
    "\n",
    "def list_checkpoints():\n",
    "    found_checkpoints = glob(os.path.join(CHECKPOINT_DIR, \"*\"))\n",
    "    found_checkpoints = [os.path.split(filename)[1] for filename in found_checkpoints]\n",
    "    print(f\"Found {len(found_checkpoints)} checkpoint files in dir '{CHECKPOINT_DIR}'\")\n",
    "    return found_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_concat = load_checkpoint(\"Cropseq_20_14_revision3_murine__seurat_Singlets.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_op = phate.PHATE(n_jobs=-1)\n",
    "data_phate = phate_op.fit_transform(adata_concat.obsm[\"X_pca\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_concat.obsm[\"X_phate\"] =  data_phate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.scatter(adata_concat, basis=\"phate\", color=\"seurat_clusters\", size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_densities = meld.MELD().fit_transform(adata_concat.obsm[\"X_pca\"], adata_concat.obs[\"gRNA_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_densities = sample_densities.rename(columns={i: f\"meld_density_{i}\" for i in sample_densities.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_densities.index = adata_concat.obs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_concat.obs = adata_concat.obs.merge(sample_densities, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.scatter(adata_concat, basis=\"phate\", color=\"meld_density_control\", size=15, color_map=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize densities to calculate sample likelihoods\n",
    "sample_likelihoods = meld.utils.normalize_densities(sample_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_likelihoods = sample_likelihoods.rename(columns={i: f\"meld_likelihood_{'_'.join(i.split('_')[2:])}\" for i in sample_densities.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_concat.obs = adata_concat.obs.merge(sample_likelihoods, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meld_df_from_target(df, target):\n",
    "    return pd.DataFrame({\n",
    "        \"target\": [target] * len(df),\n",
    "        \"meld_likelihood\": df[f\"meld_likelihood_{target}\"].to_list(),\n",
    "        \"meld_density\": df[f\"meld_density_{target}\"].to_list(),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelyhood_median(no_guide_cluster, target):\n",
    "    clusters = None\n",
    "\n",
    "    if no_guide_cluster == \"Th17\":\n",
    "        clusters = [1, 5]\n",
    "    if no_guide_cluster == \"Th1\":\n",
    "        clusters = [3]\n",
    "    if no_guide_cluster == \"Treg\":\n",
    "        clusters = [0, 6]\n",
    "\n",
    "    assert clusters is not None, \"Failed\"\n",
    "\n",
    "    return np.mean(adata_concat.obs[\n",
    "        (adata_concat.obs[\"gRNA_group\"] == \"control\") &\n",
    "        (adata_concat.obs[\"seurat_clusters\"].isin(clusters))\n",
    "    ][f\"meld_likelihood_{target}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for guide_target in list(adata_concat.obs[~adata_concat.obs[\"gRNA_group\"].isin([\"control\"])][\"gRNA_group\"].unique()):\n",
    "    # Set data\n",
    "    df = pd.DataFrame({\n",
    "        'group': [guide_target,\"Control\"],\n",
    "        'Th17': [get_likelyhood_median(\"Th17\", guide_target), get_likelyhood_median(\"Th17\", \"control\")],\n",
    "        'Th1': [get_likelyhood_median(\"Th1\", guide_target), get_likelyhood_median(\"Th1\", \"control\")],\n",
    "        'Treg': [get_likelyhood_median(\"Treg\", guide_target), get_likelyhood_median(\"Treg\", \"control\")],\n",
    "    })\n",
    "\n",
    "    # Spider chart\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_xticks(angles[:-1], categories)\n",
    "    max_value = max(max(df[\"Th17\"]), max(df[\"Th1\"]), max(df[\"Treg\"]))\n",
    "    min_value = min(min(df[\"Th17\"]), min(df[\"Th1\"]), min(df[\"Treg\"])) * 0.95\n",
    "    ax.set_rlabel_position(0)\n",
    "    ax.set_yticks(\n",
    "        [\n",
    "            min_value,\n",
    "            min_value + ((max_value - min_value) / 3),\n",
    "            min_value + ((max_value - min_value) / 3 * 2),\n",
    "            max_value\n",
    "        ],\n",
    "        [\n",
    "            str(np.round(min_value, 4)),\n",
    "            str(np.round(min_value + ((max_value - min_value) / 3), 4)),\n",
    "            str(np.round(min_value + ((max_value - min_value) / 3 * 2), 4)),\n",
    "            str(np.round(max_value, 4))\n",
    "        ],\n",
    "        color=\"grey\",\n",
    "        size=7\n",
    "    )\n",
    "    ax.set_ylim(min_value,max_value)\n",
    "    val=df.loc[0].drop('group').values.flatten().tolist()\n",
    "    val += val[:1]\n",
    "    ax.plot(angles, val, linewidth=1, linestyle='solid', label=guide_target)\n",
    "    ax.fill(angles, val, 'b', alpha=0.1)\n",
    "    val=df.loc[1].drop('group').values.flatten().tolist()\n",
    "    val += val[:1]\n",
    "    ax.plot(angles, val, linewidth=1, linestyle='solid', label=\"Control\")\n",
    "    ax.fill(angles, val, 'r', alpha=0.1)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    ax.set_title(f\"MELD likelyhook {guide_target}\")\n",
    "    fig.savefig(sfile(f\"target-{guide_target}-meld-likelihood-spiderchart.pdf\"), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "for guide_target in list(adata_concat.obs[~adata_concat.obs[\"gRNA_group\"].isin([\"control\"])][\"gRNA_group\"].unique()):\n",
    "\n",
    "    buffer_df = pd.DataFrame({\n",
    "        'group': [guide_target],\n",
    "        'Th17': [get_likelyhood_median(\"Th17\", guide_target)],\n",
    "        'Th1': [get_likelyhood_median(\"Th1\", guide_target)],\n",
    "        'Treg': [get_likelyhood_median(\"Treg\", guide_target)],\n",
    "    })\n",
    "\n",
    "    control_buffer_df = pd.DataFrame({\n",
    "        'group': [\"Control\"],\n",
    "        'Th17': [get_likelyhood_median(\"Th17\", \"control\")],\n",
    "        'Th1': [get_likelyhood_median(\"Th1\", \"control\")],\n",
    "        'Treg': [get_likelyhood_median(\"Treg\", \"control\")],\n",
    "    })\n",
    "\n",
    "    if df is None:\n",
    "        df = pd.concat([control_buffer_df, buffer_df])\n",
    "    else:\n",
    "        df = pd.concat([df, buffer_df])\n",
    "\n",
    "df.to_csv(sfile(\"median-meld-likelyhook.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
